<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>物体検出 - ONNXデモ</title>
  <style>
    body {
      font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
      margin: 0;
      padding: 20px;
      background-color: #f5f5f5;
    }
    .container {
      max-width: 800px;
      margin: 0 auto;
      background-color: white;
      padding: 20px;
      box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
      border-radius: 8px;
    }
    h1 {
      color: #333;
      text-align: center;
    }
    .video-container {
      position: relative;
      margin: 20px auto;
      max-width: 640px;
    }
    #video {
      width: 100%;
      display: block;
      border: 1px solid #ddd;
      border-radius: 4px;
    }
    #canvas {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
    }
    .controls {
      margin: 20px 0;
      text-align: center;
    }
    button {
      background-color: #4CAF50;
      border: none;
      color: white;
      padding: 10px 20px;
      text-align: center;
      text-decoration: none;
      display: inline-block;
      font-size: 16px;
      margin: 4px 2px;
      cursor: pointer;
      border-radius: 4px;
    }
    button:disabled {
      background-color: #cccccc;
      cursor: not-allowed;
    }
    .status {
      margin: 10px 0;
      padding: 10px;
      text-align: center;
      font-weight: bold;
    }
    .loading {
      color: #ff9800;
    }
    .success {
      color: #4CAF50;
    }
    .error {
      color: #f44336;
    }
    .model-info {
      margin-top: 20px;
      padding: 10px;
      background-color: #e8f5e9;
      border-radius: 4px;
    }
    #fps {
      position: absolute;
      top: 10px;
      left: 10px;
      background-color: rgba(0, 0, 0, 0.5);
      color: white;
      padding: 5px;
      border-radius: 4px;
      font-size: 14px;
    }
    #detections-info {
      margin-top: 10px;
      padding: 10px;
      background-color: #f1f8e9;
      border-radius: 4px;
      max-height: 150px;
      overflow-y: auto;
    }
  </style>
</head>
<body>
  <div class="container">
    <h1>リアルタイム物体検出デモ</h1>
    <div class="model-info">
      <h3>モデル情報</h3>
      <p>モデル名: <span id="model-name">YOLOv8n (デフォルト)</span></p>
      <p>
        <label for="model-select">モデルを選択:</label>
        <select id="model-select">
          <option value="deim_hgnetv2_s_wholebody28_ft_1250query" selected>deim_hgnetv2_s_wholebody28_ft_1250query</option>
        </select>
        <button id="load-model">モデルをロード</button>
      </p>
    </div>
    <div class="status" id="status">カメラへのアクセスを許可してください</div>
    <div class="video-container">
      <video id="video" autoplay muted playsinline></video>
      <canvas id="canvas"></canvas>
      <div id="fps">FPS: 0</div>
    </div>
    <div class="controls">
      <button id="start">開始</button>
      <button id="stop" disabled>停止</button>
    </div>
    <div id="detections-info">
      <h3>検出情報</h3>
      <div id="detection-list"></div>
    </div>
  </div>

  <!-- ONNX Runtime Web -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/onnxruntime-web/1.16.0/ort.min.js"></script>

  <script>
    // グローバル変数
    let video;
    let canvas;
    let ctx;
    let model;
    let session;
    let animationId;
    let isRunning = false;
    let lastTime = 0;
    let fps = 0;
    let frameCount = 0;
    let lastFpsUpdate = 0;

    // クラス名 (COCOデータセットの80クラス)
    const classNames = [
      'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat',
      'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat',
      'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack',
      'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',
      'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',
      'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',
      'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair',
      'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse',
      'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator',
      'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'
    ];

    // 色配列 (検出ボックスの色)
    const colors = [
      '#FF3838', '#FF9D97', '#FF701F', '#FFB21D', '#CFD231', '#48F90A', '#92CC17', '#3DDB86',
      '#1A9334', '#00D4BB', '#2C99A8', '#00C2FF', '#344593', '#6473FF', '#0018EC', '#8438FF',
      '#520085', '#CB38FF', '#FF95C8', '#FF37C7'
    ];

    // ランダムな色を取得
    const getColor = (idx) => colors[idx % colors.length];

    // DOMが読み込まれたら初期化
    document.addEventListener('DOMContentLoaded', () => {
      // 要素を取得
      video = document.getElementById('video');
      canvas = document.getElementById('canvas');
      ctx = canvas.getContext('2d');
      const startButton = document.getElementById('start');
      const stopButton = document.getElementById('stop');
      const loadModelButton = document.getElementById('load-model');
      const statusElement = document.getElementById('status');
      const fpsElement = document.getElementById('fps');

      // カメラのセットアップ
      setupCamera().then(() => {
        statusElement.textContent = 'カメラの準備完了。モデルをロードしてください。';
        statusElement.className = 'status success';
        loadModelButton.disabled = false;
      }).catch(error => {
        statusElement.textContent = `カメラエラー: ${error.message}`;
        statusElement.className = 'status error';
      });

      // モデルロードボタンのイベントリスナー
      loadModelButton.addEventListener('click', async () => {
        loadModelButton.disabled = true;
        statusElement.textContent = 'モデルをロード中...';
        statusElement.className = 'status loading';

        const modelSelect = document.getElementById('model-select');
        const modelName = modelSelect.value;
        document.getElementById('model-name').textContent = modelName;

        try {
          // モデルをロード
          await loadModel(modelName);
          statusElement.textContent = 'モデルのロード完了。検出を開始できます。';
          statusElement.className = 'status success';
          startButton.disabled = false;
        } catch (error) {
          statusElement.textContent = `モデルロードエラー: ${error.message}`;
          statusElement.className = 'status error';
          loadModelButton.disabled = false;
        }
      });

      // 開始ボタンのイベントリスナー
      startButton.addEventListener('click', () => {
        if (!isRunning) {
          startDetection();
          startButton.disabled = true;
          stopButton.disabled = false;
          statusElement.textContent = '検出実行中...';
        }
      });

      // 停止ボタンのイベントリスナー
      stopButton.addEventListener('click', () => {
        if (isRunning) {
          stopDetection();
          startButton.disabled = false;
          stopButton.disabled = true;
          statusElement.textContent = '検出停止。';
        }
      });
    });

    // カメラのセットアップ
    async function setupCamera() {
      const constraints = {
        video: {
          facingMode: 'environment',
          width: { ideal: 640 },
          height: { ideal: 480 }
        }
      };

      const stream = await navigator.mediaDevices.getUserMedia(constraints);
      video.srcObject = stream;

      return new Promise((resolve) => {
        video.onloadedmetadata = () => {
          canvas.width = video.videoWidth;
          canvas.height = video.videoHeight;
          resolve();
        };
      });
    }

    // モデルのロード
    async function loadModel(modelName) {
      try {
        // モデルのURLを設定
        const modelUrl = `./models/${modelName}.onnx`;

        // ONNXランタイムオプション
        const options = {
          executionProviders: ['wasm'],
          graphOptimizationLevel: 'all'
        };

        // セッションを作成
        session = await ort.InferenceSession.create(modelUrl, options);

        console.log('モデルのロード完了:', modelName);
        return session;
      } catch (error) {
        console.error('モデルロードエラー:', error);
        throw error;
      }
    }

    // 検出処理の開始
    function startDetection() {
      if (!session) {
        alert('モデルがロードされていません。');
        return;
      }

      isRunning = true;
      lastTime = performance.now();
      frameCount = 0;
      lastFpsUpdate = lastTime;

      // 検出ループを開始
      detectFrame();
    }

    // 検出処理の停止
    function stopDetection() {
      isRunning = false;
      if (animationId) {
        cancelAnimationFrame(animationId);
        animationId = null;
      }
    }

    // フレームごとの検出処理
    async function detectFrame() {
      if (!isRunning) return;

      const currentTime = performance.now();
      const elapsed = currentTime - lastTime;
      lastTime = currentTime;

      // FPS計算（500ms毎に更新）
      frameCount++;
      if (currentTime - lastFpsUpdate >= 500) {
        fps = Math.round((frameCount * 1000) / (currentTime - lastFpsUpdate));
        document.getElementById('fps').textContent = `FPS: ${fps}`;
        frameCount = 0;
        lastFpsUpdate = currentTime;
      }

      // 検出実行
      try {
        // ビデオフレームを処理
        const [inputTensor, inputDims] = await preprocess(video);

        // 推論実行
        const result = await runInference(inputTensor, inputDims);

        // 結果を描画
        drawDetections(result, inputDims);
      } catch (error) {
        console.error('検出エラー:', error);
      }

      // 次のフレームをリクエスト
      animationId = requestAnimationFrame(detectFrame);
    }

    // 前処理
    async function preprocess(videoElement) {
      // キャンバスサイズをビデオに合わせる
      const width = videoElement.videoWidth;
      const height = videoElement.videoHeight;

      // モデルの入力サイズ
      const modelInputSize = 640;

      // 一時的なキャンバスを作成
      const tempCanvas = document.createElement('canvas');
      tempCanvas.width = modelInputSize;
      tempCanvas.height = modelInputSize;
      const tempCtx = tempCanvas.getContext('2d');

      // アスペクト比を維持したリサイズのためのパラメータを計算
      const scale = Math.min(modelInputSize / width, modelInputSize / height);
      const scaledWidth = Math.round(width * scale);
      const scaledHeight = Math.round(height * scale);
      const dx = (modelInputSize - scaledWidth) / 2;
      const dy = (modelInputSize - scaledHeight) / 2;

      // 黒背景でクリア
      tempCtx.fillStyle = '#000';
      tempCtx.fillRect(0, 0, modelInputSize, modelInputSize);

      // ビデオフレームを描画
      tempCtx.drawImage(
        videoElement,
        0, 0, width, height,
        dx, dy, scaledWidth, scaledHeight
      );

      // 画像データを取得
      const imageData = tempCtx.getImageData(0, 0, modelInputSize, modelInputSize);
      const data = imageData.data;

      // Float32Arrayを作成
      const inputArray = new Float32Array(3 * modelInputSize * modelInputSize);

      // RGBチャネルに変換しノーマライズ (0-255 -> 0-1)
      for (let i = 0; i < modelInputSize * modelInputSize; i++) {
        // RGBをHWCからCHWに変換（PyTorchモデルは通常CHW形式）
        inputArray[i] = data[i * 4] / 255.0;                        // R
        inputArray[i + modelInputSize * modelInputSize] = data[i * 4 + 1] / 255.0;    // G
        inputArray[i + 2 * modelInputSize * modelInputSize] = data[i * 4 + 2] / 255.0;  // B
      }

      // ONNX用のテンソルを作成
      const inputTensor = new ort.Tensor('float32', inputArray, [1, 3, modelInputSize, modelInputSize]);

      // 入力次元情報（スケーリングファクタなど）を返す
      const inputDims = {
        width: width,
        height: height,
        scaledWidth: scaledWidth,
        scaledHeight: scaledHeight,
        dx: dx,
        dy: dy,
        scale: scale,
        modelInputSize: modelInputSize
      };

      return [inputTensor, inputDims];
    }

    // 推論実行
    async function runInference(inputTensor, inputDims) {
      // 入力名を取得（モデルによって異なる場合があります）
      const inputName = session.inputNames[0];

      // 推論実行
      const feeds = {};
      feeds[inputName] = inputTensor;

      // 推論結果を取得
      const results = await session.run(feeds);

      // 出力名を取得
      const outputName = session.outputNames[0];
      const output = results[outputName];

      return processResults(output, inputDims);
    }

    // 結果の処理
    function processResults(output, inputDims) {
      const { modelInputSize, scale, dx, dy } = inputDims;
      const detections = [];

      // DEIM-Wholebody output: [1,1250,6]
      // (x, y, width, height, confidence, class probabilities...)
      const data = output.data;
      const dimensions = output.dims;

      let numDetections, numClasses;

      // 出力テンソルの次元に応じて処理を分岐
      if (dimensions.length === 3) {
        // YOLOv8形式: [1, num_detections, 4+1+num_classes]
        numDetections = dimensions[1];
        numClasses = dimensions[2] - 5;
      } else if (dimensions.length === 2) {
        // 別の形式: [num_detections, 4+1+num_classes]
        numDetections = dimensions[0];
        numClasses = dimensions[1] - 5;
      } else {
        console.error('未対応の出力形式:', dimensions);
        return detections;
      }

      // 検出結果をループ処理
      for (let i = 0; i < numDetections; i++) {
        const base = i * (numClasses + 5);
        const confidence = data[base + 4];

        // 閾値以上の検出のみ処理
        if (confidence < 0.25) continue;

        // クラス確率を取得
        let maxScore = 0;
        let classId = -1;

        for (let j = 0; j < numClasses; j++) {
          const score = data[base + 5 + j];
          if (score > maxScore) {
            maxScore = score;
            classId = j;
          }
        }

        // 最終スコア
        const score = confidence * maxScore;

        // 閾値以上のスコアのみ
        if (score < 0.25) continue;

        // バウンディングボックス座標を取得
        let x = data[base];
        let y = data[base + 1];
        let w = data[base + 2];
        let h = data[base + 3];

        // モデル入力座標から元の画像座標に変換
        // スケーリングと余白を考慮して逆変換
        const x1 = (x - w/2 - dx) / scale;
        const y1 = (y - h/2 - dy) / scale;
        const x2 = (x + w/2 - dx) / scale;
        const y2 = (y + h/2 - dy) / scale;

        // 検出結果を追加
        detections.push({
          bbox: [x1, y1, x2, y2],
          class: classId,
          score: score
        });
      }

      // Non-Maximum Suppression (NMS)を適用
      return doNMS(detections, 0.45);
    }

    // Non-Maximum Suppression (NMS)
    function doNMS(detections, nmsThreshold) {
      // スコア順にソート
      const sortedDetections = [...detections].sort((a, b) => b.score - a.score);
      const selected = [];

      const isSelected = new Array(sortedDetections.length).fill(false);

      for (let i = 0; i < sortedDetections.length; i++) {
        if (isSelected[i]) continue;

        selected.push(sortedDetections[i]);
        isSelected[i] = true;

        // 現在の検出と他の全ての検出のIoUを計算
        for (let j = i + 1; j < sortedDetections.length; j++) {
          if (isSelected[j]) continue;

          // 同じクラスのみNMSを適用
          if (sortedDetections[i].class !== sortedDetections[j].class) continue;

          const iou = calculateIoU(sortedDetections[i].bbox, sortedDetections[j].bbox);

          if (iou > nmsThreshold) {
            isSelected[j] = true;
          }
        }
      }

      return selected;
    }

    // IOU（Intersection over Union）の計算
    function calculateIoU(boxA, boxB) {
      const [x1A, y1A, x2A, y2A] = boxA;
      const [x1B, y1B, x2B, y2B] = boxB;

      // 交差部分の座標を計算
      const xLeft = Math.max(x1A, x1B);
      const yTop = Math.max(y1A, y1B);
      const xRight = Math.min(x2A, x2B);
      const yBottom = Math.min(y2A, y2B);

      // 交差部分のサイズを計算
      const intersectionArea = Math.max(0, xRight - xLeft) * Math.max(0, yBottom - yTop);

      // 各ボックスの面積を計算
      const boxAArea = (x2A - x1A) * (y2A - y1A);
      const boxBArea = (x2B - x1B) * (y2B - y1B);

      // IOU = 交差部分の面積 / 合併部分の面積
      return intersectionArea / (boxAArea + boxBArea - intersectionArea);
    }

    // 検出結果の描画
    function drawDetections(detections, inputDims) {
      const { width, height } = inputDims;

      // キャンバスをクリア
      ctx.clearRect(0, 0, canvas.width, canvas.height);

      // 検出結果リストを更新
      const detectionList = document.getElementById('detection-list');
      detectionList.innerHTML = '';

      if (detections.length === 0) {
        detectionList.innerHTML = '<p>検出結果なし</p>';
      }

      // 各検出結果を描画
      detections.forEach((detection, idx) => {
        const [x1, y1, x2, y2] = detection.bbox;
        const classId = detection.class;
        const score = detection.score;
        const label = classNames[classId] || `Class ${classId}`;
        const color = getColor(classId);

        // バウンディングボックスを描画
        ctx.lineWidth = 3;
        ctx.strokeStyle = color;
        ctx.strokeRect(x1, y1, x2 - x1, y2 - y1);

        // 背景付きラベルを描画
        ctx.font = '16px Arial';
        const textWidth = ctx.measureText(`${label} ${(score * 100).toFixed(1)}%`).width;
        ctx.fillStyle = color;
        ctx.fillRect(x1, y1 - 20, textWidth + 10, 20);
        ctx.fillStyle = 'white';
        ctx.fillText(`${label} ${(score * 100).toFixed(1)}%`, x1 + 5, y1 - 5);

        // 検出リストに追加
        detectionList.innerHTML += `
          <div style="margin: 5px 0; border-left: 4px solid ${color}; padding-left: 5px;">
            ${label}: ${(score * 100).toFixed(1)}%
          </div>
        `;
      });
    }
  </script>
</body>
</html>
